{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import ahocorasick\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from nltk.corpus import stopwords, words, names\n",
    "stops = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv_to_list(filename):\n",
    "\twith open(filename) as f:  # relevant english words\n",
    "\t\treader = csv.reader(f)\n",
    "\t\tcsv_list = list(reader)\n",
    "\tcsv_list = [c[0] for c in csv_list]\n",
    "\treturn(csv_list)\n",
    "\n",
    "def init_automaton(string_list):\n",
    "\t\"\"\"Make Aho-Corasick automaton from a list of strings\"\"\"\n",
    "\tA = ahocorasick.Automaton()\n",
    "\tfor idx, s in enumerate(string_list):\n",
    "\t\tA.add_word(s, (idx, s))\n",
    "\treturn A\n",
    "\n",
    "def check_strings(A, search_list, string_to_search):\n",
    "\t\"\"\"Use Aho Corasick algorithm to produce boolean list indicating\n",
    "\tprescence of strings within a longer string\"\"\"\n",
    "\tindex_list = []\n",
    "\tfor item in A.iter(string_to_search):\n",
    "\t\tindex_list.append(item[1][0])\n",
    "\n",
    "\toutput_list = np.array([0] * len(search_list))\n",
    "\toutput_list[index_list] = 1\n",
    "\treturn output_list.tolist()\n",
    "\n",
    "def build_url_feature_vector(A_company, search_list, string_to_search):\n",
    "\t\"\"\"Presence of search_list words in string, along with length of string\"\"\"\n",
    "\tfeature_vector = check_strings(A_company, search_list, string_to_search)\n",
    "\tfeature_vector.append(len(string_to_search))\n",
    "\treturn feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load list of keywords\n",
    "words_list = read_csv_to_list('data/word_feature_list.csv')\n",
    "words_list = [w for w in words_list if w not in stops if len(w) > 1]\n",
    "url_endings_list = read_csv_to_list('data/domains_endings.csv')\n",
    "words_list = words_list + url_endings_list\n",
    "del url_endings_list\n",
    "\n",
    "A = init_automaton(words_list)\n",
    "A.make_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Test URL list\n",
    "links_df = pd.read_csv('data/links_dataframe.csv')\n",
    "url_list = links_df['url'].tolist()\n",
    "url_list = [l.replace(\"http://\", \"\").replace(\"https://\", \"\") for l in url_list if type(l) is str if l[-4:] not in [\".png\", \".jpg\", \".pdf\", \".txt\"]]\n",
    "url_list = url_list[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10703611373901367\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "next_state_list = [build_url_feature_vector(A, words_list, l) for l in url_list]\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "any(word in url_list for i in b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
