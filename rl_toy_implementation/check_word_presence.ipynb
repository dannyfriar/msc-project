{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import ahocorasick\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from nltk.corpus import stopwords, words, names\n",
    "stops = stopwords.words(\"english\")\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_automaton(string_list):\n",
    "\t\"\"\"Make Aho-Corasick automaton from a list of strings\"\"\"\n",
    "\tA = ahocorasick.Automaton()\n",
    "\tfor idx, s in enumerate(string_list):\n",
    "\t\tA.add_word(s, (idx, s))\n",
    "\treturn A\n",
    "\n",
    "def check_strings(A, search_list, string_to_search):\n",
    "    \"\"\"Use Aho Corasick algorithm to produce boolean list indicating\n",
    "    prescence of strings within a longer string\"\"\"\n",
    "    index_list = []\n",
    "    for item in A.iter(string_to_search):\n",
    "        index_list.append(item[1][0])\n",
    "\n",
    "    output_list = np.array([0] * len(search_list))\n",
    "    output_list[index_list] = 1\n",
    "    return output_list.tolist()\n",
    "\n",
    "def count_strings(A, search_list, string_to_search):\n",
    "    \"\"\"Use Aho Corasick algorithm to produce boolean list indicating\n",
    "    prescence of strings within a longer string\"\"\"\n",
    "    index_list = []\n",
    "    for item in A.iter(string_to_search):\n",
    "        index_list.append(item[1][0])\n",
    "        \n",
    "    indices = list(map(int, Counter(index_list).keys()))\n",
    "    values = np.array(list(map(int, Counter(index_list).values())))\n",
    "\n",
    "    output_list = np.array([0] * len(search_list))\n",
    "    output_list[indices] = values\n",
    "    return output_list.tolist()\n",
    "\n",
    "def progress_bar(value, endvalue, bar_length=20):\n",
    "    \"\"\"Print progress bar to the console\"\"\"\n",
    "    percent = float(value) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    sys.stdout.write(\"\\rPercent complete: [{0}] {1}%\".format(arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##-------------------- Read in data\n",
    "#Â Company i.e. reward URLs\n",
    "companies_df = pd.read_csv('../data/domains_clean.csv')\n",
    "companies_df = companies_df[companies_df['vert_code'] <= 69203]\n",
    "companies_df = companies_df[companies_df['vert_code'] >= 69101]\n",
    "reward_urls = companies_df['url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links_df = pd.read_csv('data/links_dataframe.csv')\n",
    "url_list = links_df['url'].tolist()\n",
    "url_list = [l.replace(\"http://\", \"\").replace(\"https://\", \"\") for l in url_list if type(l) is str if l[-4:] not in [\".png\", \".jpg\", \".pdf\", \".txt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##------------------------ Read in words list and build automaton\n",
    "word_list = words.words() + names.words()\n",
    "word_list = [w for w in word_list if w not in stops]\n",
    "word_list = [w for w in word_list if len(w) > 1]\n",
    "A = init_automaton(word_list)\n",
    "A.make_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# short_url_list = random.sample(url_list, 100000)\n",
    "joined_urls = \" \".join(url_list)\n",
    "word_count_vec = count_strings(A, word_list, joined_urls)\n",
    "\n",
    "# # url_list = url_list[:100]\n",
    "# word_count_vec = [0] * len(word_list)\n",
    "# for idx, url in enumerate(reward_urls):\n",
    "#     progress_bar(idx+1, len(reward_urls))\n",
    "#     word_count_vec = list(map(add, word_count_vec, np.array(check_strings(A, word_list, url))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74856</th>\n",
       "      <td>gallery</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130141</th>\n",
       "      <td>oint</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64904</th>\n",
       "      <td>ester</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236334</th>\n",
       "      <td>small</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171144</th>\n",
       "      <td>rout</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117577</th>\n",
       "      <td>mite</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28382</th>\n",
       "      <td>cad</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4529</th>\n",
       "      <td>akin</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197510</th>\n",
       "      <td>taker</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47152</th>\n",
       "      <td>customer</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210086</th>\n",
       "      <td>ule</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189835</th>\n",
       "      <td>stock</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168590</th>\n",
       "      <td>return</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105139</th>\n",
       "      <td>lection</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44541</th>\n",
       "      <td>course</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199052</th>\n",
       "      <td>technology</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236168</th>\n",
       "      <td>open</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228204</th>\n",
       "      <td>vestment</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15961</th>\n",
       "      <td>auto</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128298</th>\n",
       "      <td>nth</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75912</th>\n",
       "      <td>gaz</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136535</th>\n",
       "      <td>oyer</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78537</th>\n",
       "      <td>gol</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138561</th>\n",
       "      <td>para</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59679</th>\n",
       "      <td>eel</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119625</th>\n",
       "      <td>mortgage</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236297</th>\n",
       "      <td>see</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235968</th>\n",
       "      <td>food</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198252</th>\n",
       "      <td>target</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198249</th>\n",
       "      <td>targe</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119605</th>\n",
       "      <td>mort</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113847</th>\n",
       "      <td>menu</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98499</th>\n",
       "      <td>ism</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157517</th>\n",
       "      <td>prote</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161688</th>\n",
       "      <td>quest</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235916</th>\n",
       "      <td>education</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27920</th>\n",
       "      <td>butt</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208512</th>\n",
       "      <td>tua</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236277</th>\n",
       "      <td>round</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162646</th>\n",
       "      <td>rag</td>\n",
       "      <td>1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12920</th>\n",
       "      <td>area</td>\n",
       "      <td>1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171076</th>\n",
       "      <td>roun</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231428</th>\n",
       "      <td>whats</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36836</th>\n",
       "      <td>city</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236270</th>\n",
       "      <td>road</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112960</th>\n",
       "      <td>meet</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80754</th>\n",
       "      <td>gul</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33410</th>\n",
       "      <td>chamber</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204908</th>\n",
       "      <td>tour</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225801</th>\n",
       "      <td>urf</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62797</th>\n",
       "      <td>entia</td>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235850</th>\n",
       "      <td>copy</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48291</th>\n",
       "      <td>dal</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72012</th>\n",
       "      <td>fore</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38567</th>\n",
       "      <td>code</td>\n",
       "      <td>1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198849</th>\n",
       "      <td>tche</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67911</th>\n",
       "      <td>fair</td>\n",
       "      <td>1109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235848</th>\n",
       "      <td>cook</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235915</th>\n",
       "      <td>edge</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74831</th>\n",
       "      <td>gall</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  count\n",
       "74856      gallery   1002\n",
       "130141        oint   1004\n",
       "64904        ester   1005\n",
       "236334       small   1005\n",
       "171144        rout   1006\n",
       "117577        mite   1006\n",
       "28382          cad   1007\n",
       "4529          akin   1009\n",
       "197510       taker   1010\n",
       "47152     customer   1012\n",
       "210086         ule   1016\n",
       "189835       stock   1017\n",
       "168590      return   1019\n",
       "105139     lection   1020\n",
       "44541       course   1021\n",
       "199052  technology   1021\n",
       "236168        open   1023\n",
       "228204    vestment   1023\n",
       "15961         auto   1023\n",
       "128298         nth   1025\n",
       "75912          gaz   1026\n",
       "136535        oyer   1027\n",
       "78537          gol   1028\n",
       "138561        para   1028\n",
       "59679          eel   1029\n",
       "119625    mortgage   1029\n",
       "236297         see   1031\n",
       "235968        food   1035\n",
       "198252      target   1036\n",
       "198249       targe   1037\n",
       "...            ...    ...\n",
       "119605        mort   1080\n",
       "113847        menu   1080\n",
       "98499          ism   1081\n",
       "157517       prote   1081\n",
       "161688       quest   1082\n",
       "235916   education   1082\n",
       "27920         butt   1082\n",
       "208512         tua   1083\n",
       "236277       round   1085\n",
       "162646         rag   1086\n",
       "12920         area   1086\n",
       "171076        roun   1088\n",
       "231428       whats   1088\n",
       "36836         city   1092\n",
       "236270        road   1092\n",
       "112960        meet   1092\n",
       "80754          gul   1094\n",
       "33410      chamber   1095\n",
       "204908        tour   1095\n",
       "225801         urf   1097\n",
       "62797        entia   1098\n",
       "235850        copy   1099\n",
       "48291          dal   1100\n",
       "72012         fore   1102\n",
       "38567         code   1104\n",
       "198849        tche   1107\n",
       "67911         fair   1109\n",
       "235848        cook   1112\n",
       "235915        edge   1112\n",
       "74831         gall   1114\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict = OrderedDict()\n",
    "df_dict['word'] = word_list\n",
    "df_dict['count'] = word_count_vec\n",
    "df = pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "df = df[df['count'] >1000]\n",
    "len_filter = df['word'].str.len() > 2\n",
    "df = df[len_filter]\n",
    "df = df.sort_values('count', ascending=True)\n",
    "print(len(df))\n",
    "df.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('<U14') and format specifier ('%.18e')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1215\u001b[1;33m                     \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1216\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a float is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-694843422df1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     w = csv.writer(f)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     w.writerow([final_word_list])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/word_feature_list.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_word_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1217\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[0;32m   1218\u001b[0m                                     \u001b[1;34m\"format specifier ('%s')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[0;32m   1220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m             \u001b[0mfooter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfooter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Mismatch between array dtype ('<U14') and format specifier ('%.18e')"
     ]
    }
   ],
   "source": [
    "rm_words = ['ing', 'ers', 'tin', 'cit', 'tor', 'untin', 'els', 'ich']\n",
    "final_word_list = [w for w in df['word'].tolist() if w not in rm_words]\n",
    "\n",
    "f = open('data/word_.csv', 'w')\n",
    "w = csv.writer(f, delimiter = ',')\n",
    "w.writerows([x.split(',') for x in data])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
